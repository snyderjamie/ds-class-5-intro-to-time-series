{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeSeries Operations\n",
    "\n",
    "In this lesson we'll explore time shifting and resampling (grouping). Two of the most common operations with Time Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(\n",
    "    np.random.randn(10) * 10 + 500,\n",
    "    index=pd.date_range(start='2018-01-01', periods=10, freq='D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01    500.951582\n",
       "2018-01-02    496.084777\n",
       "2018-01-03    490.357086\n",
       "2018-01-04    495.445451\n",
       "2018-01-05    493.706927\n",
       "2018-01-06    505.912024\n",
       "2018-01-07    490.610043\n",
       "2018-01-08    497.658551\n",
       "2018-01-09    480.753560\n",
       "2018-01-10    487.750870\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01           NaN\n",
       "2018-01-02    500.951582\n",
       "2018-01-03    496.084777\n",
       "2018-01-04    490.357086\n",
       "2018-01-05    495.445451\n",
       "2018-01-06    493.706927\n",
       "2018-01-07    505.912024\n",
       "2018-01-08    490.610043\n",
       "2018-01-09    497.658551\n",
       "2018-01-10    480.753560\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Shfit (1)</th>\n",
       "      <th>Shift (2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>500.951582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>496.084777</td>\n",
       "      <td>500.951582</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>490.357086</td>\n",
       "      <td>496.084777</td>\n",
       "      <td>500.951582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>495.445451</td>\n",
       "      <td>490.357086</td>\n",
       "      <td>496.084777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>493.706927</td>\n",
       "      <td>495.445451</td>\n",
       "      <td>490.357086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-06</th>\n",
       "      <td>505.912024</td>\n",
       "      <td>493.706927</td>\n",
       "      <td>495.445451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-07</th>\n",
       "      <td>490.610043</td>\n",
       "      <td>505.912024</td>\n",
       "      <td>493.706927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>497.658551</td>\n",
       "      <td>490.610043</td>\n",
       "      <td>505.912024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>480.753560</td>\n",
       "      <td>497.658551</td>\n",
       "      <td>490.610043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-10</th>\n",
       "      <td>487.750870</td>\n",
       "      <td>480.753560</td>\n",
       "      <td>497.658551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Original   Shfit (1)   Shift (2)\n",
       "2018-01-01  500.951582         NaN         NaN\n",
       "2018-01-02  496.084777  500.951582         NaN\n",
       "2018-01-03  490.357086  496.084777  500.951582\n",
       "2018-01-04  495.445451  490.357086  496.084777\n",
       "2018-01-05  493.706927  495.445451  490.357086\n",
       "2018-01-06  505.912024  493.706927  495.445451\n",
       "2018-01-07  490.610043  505.912024  493.706927\n",
       "2018-01-08  497.658551  490.610043  505.912024\n",
       "2018-01-09  480.753560  497.658551  490.610043\n",
       "2018-01-10  487.750870  480.753560  497.658551"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'Original': ts,\n",
    "    'Shfit (1)': ts.shift(1),\n",
    "    'Shift (2)': ts.shift(2)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These operations are usually employed to compare the timeseries with previous values of the same time series. For example, calculating the percent change over the previous period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Shifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>500.951582</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>496.084777</td>\n",
       "      <td>500.951582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>490.357086</td>\n",
       "      <td>496.084777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>495.445451</td>\n",
       "      <td>490.357086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>493.706927</td>\n",
       "      <td>495.445451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-06</th>\n",
       "      <td>505.912024</td>\n",
       "      <td>493.706927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-07</th>\n",
       "      <td>490.610043</td>\n",
       "      <td>505.912024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>497.658551</td>\n",
       "      <td>490.610043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>480.753560</td>\n",
       "      <td>497.658551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-10</th>\n",
       "      <td>487.750870</td>\n",
       "      <td>480.753560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Original     Shifted\n",
       "2018-01-01  500.951582         NaN\n",
       "2018-01-02  496.084777  500.951582\n",
       "2018-01-03  490.357086  496.084777\n",
       "2018-01-04  495.445451  490.357086\n",
       "2018-01-05  493.706927  495.445451\n",
       "2018-01-06  505.912024  493.706927\n",
       "2018-01-07  490.610043  505.912024\n",
       "2018-01-08  497.658551  490.610043\n",
       "2018-01-09  480.753560  497.658551\n",
       "2018-01-10  487.750870  480.753560"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Original': ts,\n",
    "    'Shifted': ts.shift(1)\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01         NaN\n",
       "2018-01-02   -0.009715\n",
       "2018-01-03   -0.011546\n",
       "2018-01-04    0.010377\n",
       "2018-01-05   -0.003509\n",
       "2018-01-06    0.024721\n",
       "2018-01-07   -0.030246\n",
       "2018-01-08    0.014367\n",
       "2018-01-09   -0.033969\n",
       "2018-01-10    0.014555\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Original'] / df['Shifted']) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how much sales grew or shrank vs the previous month.\n",
    "\n",
    "This is a particularly silly example, because there's a pandas method specially intended for percentage changes: [`pct_change()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pct_change.html), so we don't even need `shift`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01         NaN\n",
       "2018-01-02   -0.009715\n",
       "2018-01-03   -0.011546\n",
       "2018-01-04    0.010377\n",
       "2018-01-05   -0.003509\n",
       "2018-01-06    0.024721\n",
       "2018-01-07   -0.030246\n",
       "2018-01-08    0.014367\n",
       "2018-01-09   -0.033969\n",
       "2018-01-10    0.014555\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifting also works with smaller periods, just changing the time of the original timestamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:15:00    500.951582\n",
       "2018-01-02 00:15:00    496.084777\n",
       "2018-01-03 00:15:00    490.357086\n",
       "2018-01-04 00:15:00    495.445451\n",
       "2018-01-05 00:15:00    493.706927\n",
       "2018-01-06 00:15:00    505.912024\n",
       "2018-01-07 00:15:00    490.610043\n",
       "2018-01-08 00:15:00    497.658551\n",
       "2018-01-09 00:15:00    480.753560\n",
       "2018-01-10 00:15:00    487.750870\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shift(1, freq='15Min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Frequency\n",
    "\n",
    "We'll now see how to change the frequency of our indexes. These will be just raw adjustments we'll do to directly modify the frequency of our data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    515.467395\n",
       "2018-01-01 01:00:00    516.777442\n",
       "2018-01-01 02:00:00    501.168494\n",
       "2018-01-01 03:00:00    510.984121\n",
       "2018-01-01 04:00:00    496.795909\n",
       "2018-01-01 05:00:00    481.157866\n",
       "2018-01-01 06:00:00    508.577581\n",
       "2018-01-01 07:00:00    512.112786\n",
       "2018-01-01 08:00:00    507.675569\n",
       "2018-01-01 09:00:00    506.803990\n",
       "Freq: H, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = pd.Series(\n",
    "    np.random.randn(10) * 10 + 500,\n",
    "    index=pd.date_range(start='2018-01-01', periods=10, freq='H'))\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    515.467395\n",
       "2018-01-01 00:45:00           NaN\n",
       "2018-01-01 01:30:00           NaN\n",
       "2018-01-01 02:15:00           NaN\n",
       "2018-01-01 03:00:00    510.984121\n",
       "2018-01-01 03:45:00           NaN\n",
       "2018-01-01 04:30:00           NaN\n",
       "2018-01-01 05:15:00           NaN\n",
       "2018-01-01 06:00:00    508.577581\n",
       "2018-01-01 06:45:00           NaN\n",
       "2018-01-01 07:30:00           NaN\n",
       "2018-01-01 08:15:00           NaN\n",
       "2018-01-01 09:00:00    506.803990\n",
       "Freq: 45T, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('45min') # this might break things. Need to be careful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    515.467395\n",
       "2018-01-01 00:45:00    515.467395\n",
       "2018-01-01 01:30:00    516.777442\n",
       "2018-01-01 02:15:00    501.168494\n",
       "2018-01-01 03:00:00    510.984121\n",
       "2018-01-01 03:45:00    510.984121\n",
       "2018-01-01 04:30:00    496.795909\n",
       "2018-01-01 05:15:00    481.157866\n",
       "2018-01-01 06:00:00    508.577581\n",
       "2018-01-01 06:45:00    508.577581\n",
       "2018-01-01 07:30:00    512.112786\n",
       "2018-01-01 08:15:00    507.675569\n",
       "2018-01-01 09:00:00    506.803990\n",
       "Freq: 45T, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('45Min', method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    515.467395\n",
       "2018-01-01 00:45:00    516.777442\n",
       "2018-01-01 01:30:00    501.168494\n",
       "2018-01-01 02:15:00    510.984121\n",
       "2018-01-01 03:00:00    510.984121\n",
       "2018-01-01 03:45:00    496.795909\n",
       "2018-01-01 04:30:00    481.157866\n",
       "2018-01-01 05:15:00    508.577581\n",
       "2018-01-01 06:00:00    508.577581\n",
       "2018-01-01 06:45:00    512.112786\n",
       "2018-01-01 07:30:00    507.675569\n",
       "2018-01-01 08:15:00    506.803990\n",
       "2018-01-01 09:00:00    506.803990\n",
       "Freq: 45T, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('45Min', method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masfreq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Convert TimeSeries to specified frequency.\n",
       "\n",
       "Optionally provide filling method to pad/backfill missing values.\n",
       "\n",
       "Returns the original data conformed to a new index with the specified\n",
       "frequency. ``resample`` is more appropriate if an operation, such as\n",
       "summarization, is necessary to represent the data at the new frequency.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "freq : DateOffset object, or string\n",
       "method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
       "    Method to use for filling holes in reindexed Series (note this\n",
       "    does not fill NaNs that already were present):\n",
       "\n",
       "    * 'pad' / 'ffill': propagate last valid observation forward to next\n",
       "      valid\n",
       "    * 'backfill' / 'bfill': use NEXT valid observation to fill\n",
       "how : {'start', 'end'}, default end\n",
       "    For PeriodIndex only, see PeriodIndex.asfreq\n",
       "normalize : bool, default False\n",
       "    Whether to reset output index to midnight\n",
       "fill_value: scalar, optional\n",
       "    Value to use for missing values, applied during upsampling (note\n",
       "    this does not fill NaNs that already were present).\n",
       "\n",
       "    .. versionadded:: 0.20.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "converted : type of caller\n",
       "\n",
       "Examples\n",
       "--------\n",
       "\n",
       "Start by creating a series with 4 one minute timestamps.\n",
       "\n",
       ">>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
       ">>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
       ">>> df = pd.DataFrame({'s':series})\n",
       ">>> df\n",
       "                       s\n",
       "2000-01-01 00:00:00    0.0\n",
       "2000-01-01 00:01:00    NaN\n",
       "2000-01-01 00:02:00    2.0\n",
       "2000-01-01 00:03:00    3.0\n",
       "\n",
       "Upsample the series into 30 second bins.\n",
       "\n",
       ">>> df.asfreq(freq='30S')\n",
       "                       s\n",
       "2000-01-01 00:00:00    0.0\n",
       "2000-01-01 00:00:30    NaN\n",
       "2000-01-01 00:01:00    NaN\n",
       "2000-01-01 00:01:30    NaN\n",
       "2000-01-01 00:02:00    2.0\n",
       "2000-01-01 00:02:30    NaN\n",
       "2000-01-01 00:03:00    3.0\n",
       "\n",
       "Upsample again, providing a ``fill value``.\n",
       "\n",
       ">>> df.asfreq(freq='30S', fill_value=9.0)\n",
       "                       s\n",
       "2000-01-01 00:00:00    0.0\n",
       "2000-01-01 00:00:30    9.0\n",
       "2000-01-01 00:01:00    NaN\n",
       "2000-01-01 00:01:30    9.0\n",
       "2000-01-01 00:02:00    2.0\n",
       "2000-01-01 00:02:30    9.0\n",
       "2000-01-01 00:03:00    3.0\n",
       "\n",
       "Upsample again, providing a ``method``.\n",
       "\n",
       ">>> df.asfreq(freq='30S', method='bfill')\n",
       "                       s\n",
       "2000-01-01 00:00:00    0.0\n",
       "2000-01-01 00:00:30    NaN\n",
       "2000-01-01 00:01:00    NaN\n",
       "2000-01-01 00:01:30    2.0\n",
       "2000-01-01 00:02:00    2.0\n",
       "2000-01-01 00:02:30    3.0\n",
       "2000-01-01 00:03:00    3.0\n",
       "\n",
       "See Also\n",
       "--------\n",
       "reindex\n",
       "\n",
       "Notes\n",
       "-----\n",
       "To learn more about the frequency strings, please see `this link\n",
       "<http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.6/site-packages/pandas/core/generic.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ts.asfreq?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these examples, we've gone from a \"less frequent\" index to a \"more frequent\" index. But we could go the other way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    502.855957\n",
       "2018-01-01 00:30:00    498.178670\n",
       "2018-01-01 01:00:00    481.810078\n",
       "2018-01-01 01:30:00    506.937012\n",
       "2018-01-01 02:00:00    503.455202\n",
       "2018-01-01 02:30:00    493.525074\n",
       "2018-01-01 03:00:00    477.763373\n",
       "2018-01-01 03:30:00    509.070876\n",
       "2018-01-01 04:00:00    513.217378\n",
       "2018-01-01 04:30:00    494.092888\n",
       "2018-01-01 05:00:00    495.190586\n",
       "2018-01-01 05:30:00    515.384765\n",
       "2018-01-01 06:00:00    507.185273\n",
       "2018-01-01 06:30:00    485.879794\n",
       "2018-01-01 07:00:00    488.165561\n",
       "2018-01-01 07:30:00    507.492558\n",
       "2018-01-01 08:00:00    500.645558\n",
       "2018-01-01 08:30:00    498.414551\n",
       "2018-01-01 09:00:00    506.548212\n",
       "2018-01-01 09:30:00    491.627167\n",
       "Freq: 30T, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = pd.Series(\n",
    "    np.random.randn(20) * 10 + 500,\n",
    "    index=pd.date_range(start='2018-01-01', periods=20, freq='30min'))\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    502.855957\n",
       "2018-01-01 02:00:00    503.455202\n",
       "2018-01-01 04:00:00    513.217378\n",
       "2018-01-01 06:00:00    507.185273\n",
       "2018-01-01 08:00:00    500.645558\n",
       "Freq: 2H, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('2H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    502.855957\n",
       "2018-01-01 02:25:00           NaN\n",
       "2018-01-01 04:50:00           NaN\n",
       "2018-01-01 07:15:00           NaN\n",
       "Freq: 145T, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('2H25min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    502.855957\n",
       "2018-01-01 02:25:00    503.455202\n",
       "2018-01-01 04:50:00    494.092888\n",
       "2018-01-01 07:15:00    488.165561\n",
       "Freq: 145T, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.asfreq('2H25min', method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, what if you want to do some more \"advanced\" filling. For example, filling the new freq values with the \"mean\"? For that, we'll use resampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "\n",
    "Resampling a timeseries is converting it to another time frequency. If you're going from high frequency to low frequency, the process is called \"downsampling\", and it involves an aggregation process. For example, you have daily sales data, and you want to aggregate it by month. You'll be \"grouping\" your daily sales per month, and you need to decide the aggregation operation to perform. For example, `sum` to get the total sales per month, or `mean` to get the average sale. Let's use an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-03    508.679819\n",
       "2018-01-09    497.012917\n",
       "2018-01-25    492.489636\n",
       "2018-02-07    493.097634\n",
       "2018-02-10    501.020459\n",
       "2018-03-01    511.552410\n",
       "2018-03-06    511.169199\n",
       "2018-04-06    496.049118\n",
       "2018-04-13    495.219019\n",
       "2018-04-20    513.710480\n",
       "2018-04-30    495.490997\n",
       "2018-05-31    493.725044\n",
       "2018-07-04    494.377761\n",
       "2018-07-05    497.025863\n",
       "2018-07-14    511.863808\n",
       "2018-08-05    500.289235\n",
       "2018-08-06    502.710773\n",
       "2018-08-27    493.514904\n",
       "2018-10-14    485.721787\n",
       "2018-10-27    509.466544\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_days_2018 = pd.date_range(start='2018-01-01', end='2018-12-31', freq='D')\n",
    "ts = pd.Series(\n",
    "    np.random.randn(20) * 10 + 500,\n",
    "    index=np.random.choice(all_days_2018, size=20))\n",
    "\n",
    "ts.sort_index(inplace=True)\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "January sales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-03    508.679819\n",
       "2018-01-09    497.012917\n",
       "2018-01-25    492.489636\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['2018-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1498.1823719972317"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['2018-01'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "February sales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-02-07    493.097634\n",
       "2018-02-10    501.020459\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['2018-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "994.1180937119402"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['2018-02'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downsampling**: We'll now use `resample` to \"group\" the sales monthly (downsampling our TimeSeries), and calculate the total sales per month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-31    1498.182372\n",
       "2018-02-28     994.118094\n",
       "2018-03-31    1022.721610\n",
       "2018-04-30    2000.469613\n",
       "2018-05-31     493.725044\n",
       "2018-06-30       0.000000\n",
       "2018-07-31    1503.267431\n",
       "2018-08-31    1496.514912\n",
       "2018-09-30       0.000000\n",
       "2018-10-31     995.188332\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.resample('M').sum() # month end is default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `M` means \"month end frequency. We could instead choose \"Month Start\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01    1498.182372\n",
       "2018-02-01     994.118094\n",
       "2018-03-01    1022.721610\n",
       "2018-04-01    2000.469613\n",
       "2018-05-01     493.725044\n",
       "2018-06-01       0.000000\n",
       "2018-07-01    1503.267431\n",
       "2018-08-01    1496.514912\n",
       "2018-09-01       0.000000\n",
       "2018-10-01     995.188332\n",
       "Freq: MS, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.resample('MS').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which would of course yield the same results, but the index contains the first day of each month. More correctly speaking, in this example, we're collecting sales of _\"the period January 2018\"_. Pandas also has a `Period` type, which we can use with the `kind` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01    1498.182372\n",
       "2018-02     994.118094\n",
       "2018-03    1022.721610\n",
       "2018-04    2000.469613\n",
       "2018-05     493.725044\n",
       "2018-06       0.000000\n",
       "2018-07    1503.267431\n",
       "2018-08    1496.514912\n",
       "2018-09       0.000000\n",
       "2018-10     995.188332\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_sales = ts.resample('M', kind='period').sum() # this is the correct period, but isn't supported as well in other libraries\n",
    "monthly_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeriodIndex(['2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06',\n",
       "             '2018-07', '2018-08', '2018-09', '2018-10'],\n",
       "            dtype='period[M]', freq='M')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_sales.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the Index is a `PeriodIndex`. Each entry in the index is of type `pd.Period`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2018-01', 'M')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_sales.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Period support basic arithmetic operations which makes them convenient to express these time ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2018-06', 'M')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Period('2018-01') + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2018-01-01 09:00', 'H')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Period('2018-01', freq='H') + 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upsampling**: With upsampling we'll convert a low-frequency time series to a higher frequency time series. We'll add more \"time points\". Let's use an example:\n",
    "\n",
    "We'll start with 3 months of sales, only 3 data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01    503.586684\n",
       "2018-02-01    488.363833\n",
       "2018-03-01    496.702451\n",
       "Freq: MS, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = pd.Series(\n",
    "    np.random.randn(3) * 10 + 500,\n",
    "    index=pd.date_range(start='2018-01-01', periods=3, freq='MS'))\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now `resample` it to be \"Semi Month\", every 15 days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01    503.586684\n",
       "2018-01-15           NaN\n",
       "2018-02-01    488.363833\n",
       "2018-02-15           NaN\n",
       "2018-03-01    496.702451\n",
       "Freq: SMS-15, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.resample('SMS').asfreq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as you can see, we have a few missing values, because we don't have data for those specific time periods. What can you do with that missing data? One option is to fill it with previous data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01    503.586684\n",
       "2018-01-15    503.586684\n",
       "2018-02-01    488.363833\n",
       "2018-02-15    488.363833\n",
       "2018-03-01    496.702451\n",
       "Freq: SMS-15, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.resample('SMS').ffill()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
